<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GenAI | Ananya Tadepalli – Professional Portfolio</title>
    <link>http://localhost:1313/tags/genai/</link>
      <atom:link href="http://localhost:1313/tags/genai/index.xml" rel="self" type="application/rss+xml" />
    <description>GenAI</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Sat, 03 Aug 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/media/icon_hu_982c5d63a71b2961.png</url>
      <title>GenAI</title>
      <link>http://localhost:1313/tags/genai/</link>
    </image>
    
    <item>
      <title>Beware of GenAI Hallucinations</title>
      <link>http://localhost:1313/blog/gen-ai/</link>
      <pubDate>Sat, 03 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/gen-ai/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;This week, for a team meeting, I was looking for a trivia question and asked ChatGPT, “How many sports will be played in the Paris Olympics 2024?” The unequivocal answer it gave was 32 and it even listed all 32 of them. But if we go to the Olympics.com, the committee will provide a list of 40 sports.  What just happened was a hallucination. ChatGPT did not have all of the details about the latest Olympics, so it assumed old data was correct and provided a confident answer.&lt;/p&gt;
&lt;p&gt;“The thing that I try to caution people the most is what we call the ‘hallucinations problem’,” Sam Altman, CEO of OpenAI, told ABC News. “The model will confidently state things as if they were facts entirely made up.&amp;quot; he continued.   
&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
